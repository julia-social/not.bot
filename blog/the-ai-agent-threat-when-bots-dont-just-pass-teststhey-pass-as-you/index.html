<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title></title>
    <meta name="description" content="not.bot - Cryptographic proof you are human. Create digital signatures that verify your identity online.">
    <link rel="stylesheet" href="/style.css">
    <link rel="icon" type="image/x-icon" href="/img/favicon.ico">
    <meta name="apple-itunes-app" content="app-id=6504499953">

    <!-- Open Graph / LinkedIn -->
    <meta property="og:type" content="article">
    <meta property="og:url" content="https://not.bot/blog/the-ai-agent-threat-when-bots-dont-just-pass-teststhey-pass-as-you/">
    <meta property="og:title" content="The AI Agent Threat: When Bots Don&#39;t Just Pass Tests—They Pass as You">
    <meta property="og:description" content="In July 2025, OpenAI&#39;s ChatGPT agent clicked through a CAPTCHA. No special prompting. No hacks. It just passed the test designed to prove you&#39;re human.

That was the beginning. What comes next is worse.

AI agents aren&#39;t just passing CAPTCHAs anymore. They&#39;re booking appointments, negotiating prices, managing emails, and conducting complex multi-step tasks autonomously. They&#39;re indistinguishable from humans in text, increasingly convincing in voice, and improving in video.

The question isn&#39;t whether AI agents can impersonate humans. They can. The question is what happens when they do it at scale.

## What AI Agents Can Do Now

**Current capabilities (January 2026):**

- Navigate websites and complete multi-step forms
- Respond to customer service queries indistinguishably from humans
- Write emails, documents, and reports in any style
- Conduct phone calls with cloned voices
- Maintain long-term relationships through text
- Schedule, reschedule, and negotiate appointments
- Process and respond to information in real-time

**In active development:**

- Video presence with realistic facial expressions
- Autonomous decision-making for complex tasks
- Multi-agent collaboration on sophisticated goals
- Persistent memory and relationship management

This isn&#39;t science fiction. It&#39;s today&#39;s product roadmaps.

## The Fraud Implications

When an AI agent can act as a convincing human, fraud scales differently:

**Volume without cost**

Previously, human impersonation required human labor. One scammer could manage a handful of romance scam relationships. One call center could handle a few hundred phishing calls per day.

AI agents remove this constraint. One operator can deploy thousands of agents, each maintaining separate &quot;relationships,&quot; each adjusting to their targets in real-time.

**Personalization at scale**

Spear phishing worked because it was targeted. Generic phishing was easily ignored. The tradeoff was that targeting required research time.

AI agents can personalize every interaction. They can research targets, craft individualized messages, and adapt to responses—all automatically, for millions of targets simultaneously.

**Persistent campaigns**

Human fraudsters burn out or move on. AI agents don&#39;t. They can maintain relationships for months or years, slowly building trust before executing.

The romance scam that takes six months to pay off? An AI agent can run thousands of those in parallel, with infinite patience.

## Agent-to-Agent Impersonation

Here&#39;s where it gets weird: AI agents can impersonate other AI agents.

As businesses deploy AI assistants and agents, those agents become targets. An AI calling your company&#39;s AI assistant, pretending to be from your bank, could extract information or authorize actions.

The question &quot;am I talking to a human?&quot; becomes &quot;am I talking to a legitimate agent?&quot;

Verification doesn&#39;t just apply to humans anymore. It applies to AI systems acting on behalf of humans.

## The Employment Fraud Scenario

Consider this attack vector:

1. AI agent applies for remote jobs at scale
2. Passes automated screening with optimized resumes
3. Does video interviews using deepfake video
4. Gets hired as a remote employee
5. Does enough work to avoid immediate detection
6. Exfiltrates data, accesses systems, or commits fraud from inside

Sound implausible? Companies are already seeing:
- Remote workers who are never available for video calls
- Employees whose work quality varies wildly (different agents?)
- Background check fraud using synthetic identities
- Multiple &quot;people&quot; controlled by single operators

The traditional hiring process assumes humans apply for jobs. That assumption is breaking.

## The Attestation Problem

Here&#39;s the fundamental issue: we have no way to verify that a digital interaction involves a human.

Every system that assumes human participants is vulnerable:

- **Social media:** designed for human communication, flooded with bot content
- **Dating apps:** designed for human connection, filled with AI catfish
- **Job platforms:** designed for human candidates, gamed by synthetic applicants
- **Customer service:** designed for human customers, abused by automated systems
- **Democracy:** designed for human voters, manipulated by bot campaigns

Humans built digital infrastructure assuming humans would use it. That assumption is no longer valid.

## Why Detection Won&#39;t Work

We&#39;ve covered this before, but it bears repeating in the agent context:

&quot;AI agent detection&quot; faces the same asymmetry problem as all detection:
- Agents that fail detection learn why and improve
- Detection systems can&#39;t learn from agents that pass

As agent capabilities improve, detection becomes increasingly difficult. Eventually, the question &quot;is this an AI agent?&quot; becomes unanswerable through observation alone.

The only reliable solution is cryptographic attestation: proof that a verified human authorized this action.

## What We Need

**Human attestation:**
&quot;This account is controlled by a verified human&quot; should be a standard credential—not revealing who the human is, just that a human exists.

**Agent attestation:**
&quot;This AI agent is authorized to act on behalf of [verified entity]&quot; should be a standard credential for legitimate agent operations.

**Interaction verification:**
&quot;This conversation has at least one verified human participant&quot; should be a possible filter for platforms that want to enable it.

**Action authorization:**
&quot;This transaction was authorized by a verified human&quot; should be available for high-stakes operations.

None of this requires surveillance. All of it can be done with cryptographic privacy. The technology exists—it&#39;s the deployment that&#39;s missing.

## The Window Is Closing

AI agent capabilities are advancing faster than our infrastructure for verification.

Every month that passes:
- Agents become more capable
- Fraud becomes more sophisticated
- The installed base of unverified systems grows larger
- The cost of retrofitting verification increases

The time to build verification infrastructure is before it&#39;s desperately needed—not after.

---

**AI agents are already passing as human.** The question isn&#39;t whether to verify humanness—it&#39;s how quickly we can deploy verification before the flood.

Detection is failing. Verification is the path forward.

That&#39;s what we&#39;re building.

---

## Sources

- [Ars Technica - OpenAI&#39;s ChatGPT agent defeats CAPTCHA](https://arstechnica.com/information-technology/2025/07/openais-chatgpt-agent-casually-clicks-through-i-am-not-a-robot-verification-test/)

---">
    
    <meta property="og:image" content="https://media.not.bot/post_fe9349a1f5.png">
    
    <meta property="og:site_name" content="not.bot">

    <!-- Twitter / X -->
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:site" content="@notbot_official">
    <meta name="twitter:title" content="The AI Agent Threat: When Bots Don&#39;t Just Pass Tests—They Pass as You">
    <meta name="twitter:description" content="In July 2025, OpenAI&#39;s ChatGPT agent clicked through a CAPTCHA. No special prompting. No hacks. It just passed the test designed to prove you&#39;re human.

That was the beginning. What comes next is worse.

AI agents aren&#39;t just passing CAPTCHAs anymore. They&#39;re booking appointments, negotiating prices, managing emails, and conducting complex multi-step tasks autonomously. They&#39;re indistinguishable from humans in text, increasingly convincing in voice, and improving in video.

The question isn&#39;t whether AI agents can impersonate humans. They can. The question is what happens when they do it at scale.

## What AI Agents Can Do Now

**Current capabilities (January 2026):**

- Navigate websites and complete multi-step forms
- Respond to customer service queries indistinguishably from humans
- Write emails, documents, and reports in any style
- Conduct phone calls with cloned voices
- Maintain long-term relationships through text
- Schedule, reschedule, and negotiate appointments
- Process and respond to information in real-time

**In active development:**

- Video presence with realistic facial expressions
- Autonomous decision-making for complex tasks
- Multi-agent collaboration on sophisticated goals
- Persistent memory and relationship management

This isn&#39;t science fiction. It&#39;s today&#39;s product roadmaps.

## The Fraud Implications

When an AI agent can act as a convincing human, fraud scales differently:

**Volume without cost**

Previously, human impersonation required human labor. One scammer could manage a handful of romance scam relationships. One call center could handle a few hundred phishing calls per day.

AI agents remove this constraint. One operator can deploy thousands of agents, each maintaining separate &quot;relationships,&quot; each adjusting to their targets in real-time.

**Personalization at scale**

Spear phishing worked because it was targeted. Generic phishing was easily ignored. The tradeoff was that targeting required research time.

AI agents can personalize every interaction. They can research targets, craft individualized messages, and adapt to responses—all automatically, for millions of targets simultaneously.

**Persistent campaigns**

Human fraudsters burn out or move on. AI agents don&#39;t. They can maintain relationships for months or years, slowly building trust before executing.

The romance scam that takes six months to pay off? An AI agent can run thousands of those in parallel, with infinite patience.

## Agent-to-Agent Impersonation

Here&#39;s where it gets weird: AI agents can impersonate other AI agents.

As businesses deploy AI assistants and agents, those agents become targets. An AI calling your company&#39;s AI assistant, pretending to be from your bank, could extract information or authorize actions.

The question &quot;am I talking to a human?&quot; becomes &quot;am I talking to a legitimate agent?&quot;

Verification doesn&#39;t just apply to humans anymore. It applies to AI systems acting on behalf of humans.

## The Employment Fraud Scenario

Consider this attack vector:

1. AI agent applies for remote jobs at scale
2. Passes automated screening with optimized resumes
3. Does video interviews using deepfake video
4. Gets hired as a remote employee
5. Does enough work to avoid immediate detection
6. Exfiltrates data, accesses systems, or commits fraud from inside

Sound implausible? Companies are already seeing:
- Remote workers who are never available for video calls
- Employees whose work quality varies wildly (different agents?)
- Background check fraud using synthetic identities
- Multiple &quot;people&quot; controlled by single operators

The traditional hiring process assumes humans apply for jobs. That assumption is breaking.

## The Attestation Problem

Here&#39;s the fundamental issue: we have no way to verify that a digital interaction involves a human.

Every system that assumes human participants is vulnerable:

- **Social media:** designed for human communication, flooded with bot content
- **Dating apps:** designed for human connection, filled with AI catfish
- **Job platforms:** designed for human candidates, gamed by synthetic applicants
- **Customer service:** designed for human customers, abused by automated systems
- **Democracy:** designed for human voters, manipulated by bot campaigns

Humans built digital infrastructure assuming humans would use it. That assumption is no longer valid.

## Why Detection Won&#39;t Work

We&#39;ve covered this before, but it bears repeating in the agent context:

&quot;AI agent detection&quot; faces the same asymmetry problem as all detection:
- Agents that fail detection learn why and improve
- Detection systems can&#39;t learn from agents that pass

As agent capabilities improve, detection becomes increasingly difficult. Eventually, the question &quot;is this an AI agent?&quot; becomes unanswerable through observation alone.

The only reliable solution is cryptographic attestation: proof that a verified human authorized this action.

## What We Need

**Human attestation:**
&quot;This account is controlled by a verified human&quot; should be a standard credential—not revealing who the human is, just that a human exists.

**Agent attestation:**
&quot;This AI agent is authorized to act on behalf of [verified entity]&quot; should be a standard credential for legitimate agent operations.

**Interaction verification:**
&quot;This conversation has at least one verified human participant&quot; should be a possible filter for platforms that want to enable it.

**Action authorization:**
&quot;This transaction was authorized by a verified human&quot; should be available for high-stakes operations.

None of this requires surveillance. All of it can be done with cryptographic privacy. The technology exists—it&#39;s the deployment that&#39;s missing.

## The Window Is Closing

AI agent capabilities are advancing faster than our infrastructure for verification.

Every month that passes:
- Agents become more capable
- Fraud becomes more sophisticated
- The installed base of unverified systems grows larger
- The cost of retrofitting verification increases

The time to build verification infrastructure is before it&#39;s desperately needed—not after.

---

**AI agents are already passing as human.** The question isn&#39;t whether to verify humanness—it&#39;s how quickly we can deploy verification before the flood.

Detection is failing. Verification is the path forward.

That&#39;s what we&#39;re building.

---

## Sources

- [Ars Technica - OpenAI&#39;s ChatGPT agent defeats CAPTCHA](https://arstechnica.com/information-technology/2025/07/openais-chatgpt-agent-casually-clicks-through-i-am-not-a-robot-verification-test/)

---">
    
    <meta name="twitter:image" content="https://media.not.bot/post_fe9349a1f5.png">
    

     
 <script defer data-domain="not.bot" src="https://analytics.not.bot/js/script.js"></script>
</head>
<body>
    <!-- Navigation -->
    <nav class="navbar">
        <div class="nav-container">
            <div class="logo">
                <a href="/index.html">
                <img src="/img/notbot_logo.svg" alt="not.bot">
                </a>
            </div>
            
            <ul class="nav-menu">
                <li class="nav-item dropdown">
                    <a href="#" class="nav-link ">Products</a>
                    <div class="dropdown-content">
                        <a href="/">not.bot</a>
                        <a href="/products/reserved_names">not.bot Reserved Names</a>
                        <a href="/products/verified_creator">not.bot Verified Creator</a>
                    </div>
                </li>
                <li class="nav-item dropdown">
                    <a href="#" class="nav-link ">Coming Soon</a>
                    <div class="dropdown-content">
                        <a href="/coming-soon/b2c">not.bot B2C</a>
                        <a class="d-none" href="/coming-soon/enterprise">not.bot Enterprise</a>
                        <a href="/coming-soon/honest-bot">honest.bot</a>
                    </div>
                </li>
                <li class="nav-item">
                    <a href="/technology" class="nav-link ">Technology</a>
                </li>
                <li class="nav-item d-none">
                    <a href="/feedback" class="nav-link">Feedback</a>
                </li>
                <li class="nav-item">
                    <a href="https://merch.not.bot/" class="nav-link" target="_blank">Merch</a>
                </li>
                <li class="nav-item">
                    <a href="/about" class="nav-link ">About</a>
                </li>
                   <li class="nav-item">
                    <a href="/blog" class="nav-link">Blog</a>
                </li>
            </ul>
            
            <button class="mobile-menu-toggle">
                <span class="hamburger"></span>
            </button>
        </div>
    </nav>

    <!-- Hero Section -->
    
  <style>
.post-detail p{
    font-size: 18px;
    margin: 15px 0;
     color:#414141
}
.post-detail img {
    width:100%;
    height:auto;
    margin-bottom:30px;
    margin-top:10px
}
.post-detail ul {
    padding-left:15px
}
.post-detail li {
    font-size: 18px;
    line-height:40px;
    color:#414141
}
.blog-detail-container {
        max-width: 800px;
    margin: 0 auto;
    padding: 0 20px;
}
blockquote {
    background: #F9F9F9;
    padding: 15px 40px;
    color: #242424;
    border-radius: 4px;
    border: 1px solid #E5E5E5;
    margin-top:50px;
}
blockquote p {
    font-size:14px !important;
}
.post-detail {
    padding-bottom:80px
}

.post-detail strong{
    font-size: 16px;
}
.post-detail h1 {
  font-size: 2.5rem;   /* ~40px */
  font-weight: 700;
   line-height: 46px;
    margin-bottom: 20px;
}

.post-detail h2 {
  font-size: 2rem;     /* ~32px */
  font-weight: 600;
line-height: 46px;
margin-bottom: 20px;
margin-top:20px;
}

.post-detail h3 {
  font-size: 1.75rem;  /* ~28px */
  font-weight: 600;
   line-height: 46px;
    margin-bottom: 20px;
}

.post-detail h4 {
  font-size: 1.5rem;   /* ~24px */
  font-weight: 500;
   line-height: 46px;
    margin-bottom: 20px;
}

.post-detail h5 {
  font-size: 1.25rem;  /* ~20px */
  font-weight: 500;
   line-height: 46px;
    margin-bottom: 20px;
}

.post-detail h6 {
  font-size: 1rem;     /* ~16px */
  font-weight: 500;
   line-height: 46px;
    margin-bottom: 20px;
}
</style>
<div class="blog-detail-container">
<div class="post-detail">
 <a href="/blog" style="display:inline-block;margin-top:2rem;color:#6366f1;margin-bottom:20px">← Back to all posts</a>
  <h1>The AI Agent Threat: When Bots Don&#39;t Just Pass Tests—They Pass as You</h1>
  <div style="color:#3386fc;;font-size:1rem;margin-bottom:1.5rem;font-weight:600">
    Published: 10 February 2026
  </div>
  
    <img src="https://media.not.bot/post_fe9349a1f5.png" alt="The AI Agent Threat: When Bots Don&#39;t Just Pass Tests—They Pass as You" style="max-width:100%;height:auto;border-radius:12px;margin-bottom:1.5rem;" />
  
  
    <div><p>In July 2025, OpenAI's ChatGPT agent clicked through a CAPTCHA. No special prompting. No hacks. It just passed the test designed to prove you're human.</p>
<p>That was the beginning. What comes next is worse.</p>
<p>AI agents aren't just passing CAPTCHAs anymore. They're booking appointments, negotiating prices, managing emails, and conducting complex multi-step tasks autonomously. They're indistinguishable from humans in text, increasingly convincing in voice, and improving in video.</p>
<p>The question isn't whether AI agents can impersonate humans. They can. The question is what happens when they do it at scale.</p>
<h2>What AI Agents Can Do Now</h2>
<p><strong>Current capabilities (January 2026):</strong></p>
<ul>
<li>Navigate websites and complete multi-step forms</li>
<li>Respond to customer service queries indistinguishably from humans</li>
<li>Write emails, documents, and reports in any style</li>
<li>Conduct phone calls with cloned voices</li>
<li>Maintain long-term relationships through text</li>
<li>Schedule, reschedule, and negotiate appointments</li>
<li>Process and respond to information in real-time</li>
</ul>
<p><strong>In active development:</strong></p>
<ul>
<li>Video presence with realistic facial expressions</li>
<li>Autonomous decision-making for complex tasks</li>
<li>Multi-agent collaboration on sophisticated goals</li>
<li>Persistent memory and relationship management</li>
</ul>
<p>This isn't science fiction. It's today's product roadmaps.</p>
<h2>The Fraud Implications</h2>
<p>When an AI agent can act as a convincing human, fraud scales differently:</p>
<p><strong>Volume without cost</strong></p>
<p>Previously, human impersonation required human labor. One scammer could manage a handful of romance scam relationships. One call center could handle a few hundred phishing calls per day.</p>
<p>AI agents remove this constraint. One operator can deploy thousands of agents, each maintaining separate &quot;relationships,&quot; each adjusting to their targets in real-time.</p>
<p><strong>Personalization at scale</strong></p>
<p>Spear phishing worked because it was targeted. Generic phishing was easily ignored. The tradeoff was that targeting required research time.</p>
<p>AI agents can personalize every interaction. They can research targets, craft individualized messages, and adapt to responses—all automatically, for millions of targets simultaneously.</p>
<p><strong>Persistent campaigns</strong></p>
<p>Human fraudsters burn out or move on. AI agents don't. They can maintain relationships for months or years, slowly building trust before executing.</p>
<p>The romance scam that takes six months to pay off? An AI agent can run thousands of those in parallel, with infinite patience.</p>
<h2>Agent-to-Agent Impersonation</h2>
<p>Here's where it gets weird: AI agents can impersonate other AI agents.</p>
<p>As businesses deploy AI assistants and agents, those agents become targets. An AI calling your company's AI assistant, pretending to be from your bank, could extract information or authorize actions.</p>
<p>The question &quot;am I talking to a human?&quot; becomes &quot;am I talking to a legitimate agent?&quot;</p>
<p>Verification doesn't just apply to humans anymore. It applies to AI systems acting on behalf of humans.</p>
<h2>The Employment Fraud Scenario</h2>
<p>Consider this attack vector:</p>
<ol>
<li>AI agent applies for remote jobs at scale</li>
<li>Passes automated screening with optimized resumes</li>
<li>Does video interviews using deepfake video</li>
<li>Gets hired as a remote employee</li>
<li>Does enough work to avoid immediate detection</li>
<li>Exfiltrates data, accesses systems, or commits fraud from inside</li>
</ol>
<p>Sound implausible? Companies are already seeing:</p>
<ul>
<li>Remote workers who are never available for video calls</li>
<li>Employees whose work quality varies wildly (different agents?)</li>
<li>Background check fraud using synthetic identities</li>
<li>Multiple &quot;people&quot; controlled by single operators</li>
</ul>
<p>The traditional hiring process assumes humans apply for jobs. That assumption is breaking.</p>
<h2>The Attestation Problem</h2>
<p>Here's the fundamental issue: we have no way to verify that a digital interaction involves a human.</p>
<p>Every system that assumes human participants is vulnerable:</p>
<ul>
<li><strong>Social media:</strong> designed for human communication, flooded with bot content</li>
<li><strong>Dating apps:</strong> designed for human connection, filled with AI catfish</li>
<li><strong>Job platforms:</strong> designed for human candidates, gamed by synthetic applicants</li>
<li><strong>Customer service:</strong> designed for human customers, abused by automated systems</li>
<li><strong>Democracy:</strong> designed for human voters, manipulated by bot campaigns</li>
</ul>
<p>Humans built digital infrastructure assuming humans would use it. That assumption is no longer valid.</p>
<h2>Why Detection Won't Work</h2>
<p>We've covered this before, but it bears repeating in the agent context:</p>
<p>&quot;AI agent detection&quot; faces the same asymmetry problem as all detection:</p>
<ul>
<li>Agents that fail detection learn why and improve</li>
<li>Detection systems can't learn from agents that pass</li>
</ul>
<p>As agent capabilities improve, detection becomes increasingly difficult. Eventually, the question &quot;is this an AI agent?&quot; becomes unanswerable through observation alone.</p>
<p>The only reliable solution is cryptographic attestation: proof that a verified human authorized this action.</p>
<h2>What We Need</h2>
<p><strong>Human attestation:</strong>
&quot;This account is controlled by a verified human&quot; should be a standard credential—not revealing who the human is, just that a human exists.</p>
<p><strong>Agent attestation:</strong>
&quot;This AI agent is authorized to act on behalf of [verified entity]&quot; should be a standard credential for legitimate agent operations.</p>
<p><strong>Interaction verification:</strong>
&quot;This conversation has at least one verified human participant&quot; should be a possible filter for platforms that want to enable it.</p>
<p><strong>Action authorization:</strong>
&quot;This transaction was authorized by a verified human&quot; should be available for high-stakes operations.</p>
<p>None of this requires surveillance. All of it can be done with cryptographic privacy. The technology exists—it's the deployment that's missing.</p>
<h2>The Window Is Closing</h2>
<p>AI agent capabilities are advancing faster than our infrastructure for verification.</p>
<p>Every month that passes:</p>
<ul>
<li>Agents become more capable</li>
<li>Fraud becomes more sophisticated</li>
<li>The installed base of unverified systems grows larger</li>
<li>The cost of retrofitting verification increases</li>
</ul>
<p>The time to build verification infrastructure is before it's desperately needed—not after.</p>
<hr>
<p><strong>AI agents are already passing as human.</strong> The question isn't whether to verify humanness—it's how quickly we can deploy verification before the flood.</p>
<p>Detection is failing. Verification is the path forward.</p>
<p>That's what we're building.</p>
<hr>
<h2>Sources</h2>
<ul>
<li><a href="https://arstechnica.com/information-technology/2025/07/openais-chatgpt-agent-casually-clicks-through-i-am-not-a-robot-verification-test/">Ars Technica - OpenAI's ChatGPT agent defeats CAPTCHA</a></li>
</ul>
<hr>
</div>
  
  
 
</div>
</div>

    
    <!-- Footer -->
    <footer class="footer">
    <div class="signup-band">
        <div class="signup-container">
            <form class="signup-form" id="waitlist-form">
                <label for="waitlist-email">Join Waitlist</label>
                <div class="form-group">
                    <input type="email" id="waitlist-email" name="email" placeholder="Enter your email" required>
                    <button id="waitlist-submit" type="submit">Join Waitlist</button>
                </div>
            </form>
            <form class="signup-form" id="newsletter-form">
                <label for="newsletter-email">Newsletter</label>
                <div class="form-group">
                    <input type="email" id="newsletter-email" name="email" placeholder="Enter your email" required>
                    <button id="newsletter-submit" type="submit">Subscribe</button>
                </div>
            </form>
        </div>
    </div>
    <!-- Main Footer -->
    <div class="footer-main">
        <div
            class="footer-container">
            <!-- Contact Column -->
            <div class="footer-contact">
                <h4 class="footer-heading">Contact</h4>
                <a href="mailto:hello@julia.social" class="footer-email" style="margin-bottom:0px;">hello@julia.social</a>
                <div class="julia-logo" style="margin-bottom:0px;">
                    <img src="/img/julia_logo.svg" alt="Julia Social">
                </div>
                <div class="copyright">
                    Copyright 2025, Julia Social Inc
                </div>
            </div>
            <!-- Legal Links Column -->
            <div class="footer-legal">
                <h4 class="footer-heading">Legal</h4>
                <ul>
                    <li><a href="not.bot_PrivacyPolicy.html" target="_blank">Privacy Policy</a></li>
                    <li><a href="not.bot_terms_of_use.html" target="_blank">Terms of Use</a></li>
                    <li><a href="no_cookies.html" target="_blank">No Cookies Policy</a></li>
            </div>
            <div class="social-links">
                <h4 class="footer-heading">Follow Us</h4>
                <div class="social-links-list">
                    <a
                        href="https://x.com/notbot_official" class="social-link" target="_blank">
                        <!-- X (Twitter) Icon -->
                        <svg class="social-icon" viewbox="0 0 24 24">
                            <path d="M18.244 2.25h3.308l-7.227 8.26 8.502 11.24H16.17l-5.214-6.817L4.99 21.75H1.68l7.73-8.835L1.254 2.25H8.08l4.713
                            6.231zm-1.161 17.52h1.833L7.084 4.126H5.117z"/>
                        </svg>
                        not.bot
                    </a>
                    <a
                        href="https://discord.gg/2Un6yJSDvV" class="social-link" target="_blank">
                        <!-- Discord Icon -->
                        <svg class="social-icon" viewbox="0 0 24 24">
                            <path d="M20.317 4.37a19.791 19.791 0 0 0-4.885-1.515.074.074 0 0 0-.079.037c-.21.375-.444.864-.608 1.25a18.27 18.27 0 0
                            0-5.487 0 12.64 12.64 0 0 0-.617-1.25.077.077 0 0 0-.079-.037A19.736 19.736 0 0 0 3.677 4.37a.07.07 0 0 0-.032.027C.533
                            9.046-.32 13.58.099 18.057a.082.082 0 0 0 .031.057 19.9 19.9 0 0 0 5.993 3.03.078.078 0 0 0 .084-.028 14.09 14.09 0 0 0
                            1.226-1.994.076.076 0 0 0-.041-.106 13.107 13.107 0 0 1-1.872-.892.077.077 0 0 1-.008-.128 10.2 10.2 0 0 0
                            .372-.292.074.074 0 0 1 .077-.01c3.928 1.793 8.18 1.793 12.062 0a.074.074 0 0 1 .078.01c.12.098.246.191.373.292a.077.077
                            0 0 1-.006.127 12.299 12.299 0 0 1-1.873.892.077.077 0 0 0-.041.107c.36.698.772 1.362 1.225 1.993a.076.076 0 0 0 .084.028
                            19.839 19.839 0 0 0 6.002-3.03.077.077 0 0 0 .032-.054c.5-5.177-.838-9.674-3.549-13.66a.061.061 0 0 0-.031-.03zM8.02
                            15.33c-1.183 0-2.157-1.085-2.157-2.419 0-1.333.956-2.419 2.157-2.419 1.21 0 2.176 1.096 2.157 2.42 0 1.333-.956
                            2.418-2.157 2.418zm7.975 0c-1.183 0-2.157-1.085-2.157-2.419 0-1.333.955-2.419 2.157-2.419 1.21 0 2.176 1.096 2.157 2.42 0
                            1.333-.946 2.418-2.157 2.418z"/>
                        </svg>
                        Discord
                    </a>
                    <a
                        href="https://www.linkedin.com/company/julia-social/" class="social-link" target="_blank">
                        <!-- LinkedIn Icon -->
                        <svg class="social-icon" viewbox="0 0 24 24">
                            <path d="M20.447 20.452h-3.554v-5.569c0-1.328-.027-3.037-1.852-3.037-1.853 0-2.136 1.445-2.136
                            2.939v5.667H9.351V9h3.414v1.561h.046c.477-.9 1.637-1.85 3.37-1.85 3.601 0 4.267 2.37 4.267 5.455v6.286zM5.337
                            7.433c-1.144 0-2.063-.926-2.063-2.065 0-1.138.92-2.063 2.063-2.063 1.14 0 2.064.925 2.064 2.063 0 1.139-.925 2.065-2.064
                            2.065zm1.782 13.019H3.555V9h3.564v11.452zM22.225 0H1.771C.792 0 0 .774 0 1.729v20.542C0 23.227.792 24 1.771
                            24h20.451C23.2 24 24 23.227 24 22.271V1.729C24 .774 23.2 0 22.222 0h.003z"/>
                        </svg>
                        LinkedIn
                    </a>
                    <a
                        href="https://github.com/julia-social" class="social-link" target="_blank">
                        <!-- GitHub Icon -->
                        <svg class="social-icon" viewbox="0 0 24 24">
                            <path d="M12 0c-6.626 0-12 5.373-12 12 0 5.302 3.438 9.8 8.207
                            11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729
                            1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304
                            3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381
                            1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138
                            3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807
                            5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576 4.765-1.589 8.199-6.086 8.199-11.386
                            0-6.627-5.373-12-12-12z"/>
                        </svg>
                        GitHub
                    </a>
                </div>
            </div>
            </div>
            <!-- Social Links Column -->
            
        </div>
    </div>
    <!-- Modal -->
    <div id="modal" class="modal">
        <div class="modal-content">
            <div class="modal-message" id="modalMessage"></div>
            <button class="modal-close" id="modalClose">OK</button>
        </div>
    </div>
    <script>
        // Email validation
        function isValidEmail(email) {
            return email.includes('@') && email.includes('.') && email.trim() !== '';
        }

        const modal = document.getElementById('modal');
        const modalMessage = document.getElementById('modalMessage');
        const modalClose = document.getElementById('modalClose');

        // Modal close
        modalClose.addEventListener('click', function() {
            modal.style.display = 'none';
        });
        // Close modal when clicking outside
        window.addEventListener('click', function(event) {
            if (event.target === modal) {
                modal.style.display = 'none';
            }
        });

        // WaitList Form handling
        const waitListInput = document.getElementById('waitlist-email');
        const waitListSubmitBtn = document.getElementById('waitlist-submit');
        const waitListSignupForm = document.getElementById('waitlist-form');

        // Enable/disable submit button based on input
        waitListInput.addEventListener('input', function() {
            const email = this.value.trim();
            waitListSubmitBtn.disabled = !isValidEmail(email);
        });

        // WaitList Form submission
        waitListSignupForm.addEventListener('submit', async function(e) {
            e.preventDefault();
            const email = waitListInput.value.trim();
            if (!isValidEmail(email)) {
                return;
            }
            waitListSubmitBtn.disabled = true;
            waitListSubmitBtn.textContent = 'Submitting...';
            try {
                const formData = new FormData();
                formData.append('email', email);
                const response = await fetch('https://not-bot-referral-form.restless-unit-5918.workers.dev', {
                    method: 'POST',
                    body: formData
                });
                if (response.ok) {
                    modalMessage.textContent = 'Subscribed. Welcome to Not.Bot!';
                    waitListInput.value = '';
                } else {
                    modalMessage.textContent = 'Failed to subscribe. Please try again later.';
                }
            } catch (error) {
                modalMessage.textContent = 'Failed to subscribe. Please try again later.';
            }
            modal.style.display = 'block';
            waitListSubmitBtn.disabled = !isValidEmail(waitListInput.value.trim());
            waitListSubmitBtn.textContent = 'Submit';
        });

        // Newsletter Form handling
        const newsletterInput = document.getElementById('newsletter-email');
        const newsletterSubmitBtn = document.getElementById('newsletter-submit');
        const newsletterSignupForm = document.getElementById('newsletter-form');

        // Enable/disable submit button based on input
        newsletterInput.addEventListener('input', function() {
            const email = this.value.trim();
            newsletterSubmitBtn.disabled = !isValidEmail(email);
        });

        // Form submission
        newsletterSignupForm.addEventListener('submit', async function(e) {
            e.preventDefault();
            const email = newsletterInput.value.trim();
            if (!isValidEmail(email)) {
                return;
            }
            newsletterSubmitBtn.disabled = true;
            newsletterSubmitBtn.textContent = 'Submitting...';
            try {
                const formData = new FormData();
                formData.append('email', email);
                const response = await fetch('https://not-bot-email-form.restless-unit-5918.workers.dev', {
                    method: 'POST',
                    body: formData
                });
                if (response.ok) {
                    modalMessage.textContent = 'Subscribed. Welcome to Not.Bot!';
                    newsletterInput.value = '';
                } else {
                    modalMessage.textContent = 'Failed to subscribe. Please try again later.';
                }
            } catch (error) {
                modalMessage.textContent = 'Failed to subscribe. Please try again later.';
            }
            modal.style.display = 'block';
            newsletterSubmitBtn.disabled = !isValidEmail(newsletterInput.value.trim());
            newsletterSubmitBtn.textContent = 'Submit';
        });
    </script>
</footer>

<script type="text/javascript">
// Mobile menu toggle functionality
        const mobileMenuToggle = document.querySelector('.mobile-menu-toggle');
        const navMenu = document.querySelector('.nav-menu');

        mobileMenuToggle.addEventListener('click', function() {
            navMenu.classList.toggle('active');
            mobileMenuToggle.classList.toggle('active');
        });

        // Mobile dropdown functionality
        const dropdowns = document.querySelectorAll('.dropdown');
        
        dropdowns.forEach(dropdown => {
            const link = dropdown.querySelector('.nav-link');
            
            link.addEventListener('click', function(e) {
                if (window.innerWidth <= 900) {
                    e.preventDefault();
                    dropdown.classList.toggle('active');
                }
            });
        });

        // Close mobile menu when clicking on dropdown items
        const dropdownLinks = document.querySelectorAll('.dropdown-content a');
        dropdownLinks.forEach(link => {
            link.addEventListener('click', function() {
                if (window.innerWidth <= 900) {
                    navMenu.classList.remove('active');
                    mobileMenuToggle.classList.remove('active');
                    // Close all dropdowns
                    dropdowns.forEach(d => d.classList.remove('active'));
                }
            });
        });

        // Handle window resize
        window.addEventListener('resize', function() {
            if (window.innerWidth > 900) {
                navMenu.classList.remove('active');
                mobileMenuToggle.classList.remove('active');
                dropdowns.forEach(d => d.classList.remove('active'));
            }
        });
    </script>
    
</body>
</html>